{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1EckV22lRkew"
      },
      "source": [
        "# Instrucciones para correr el programa\n",
        "\n",
        "1) Carga de base de datos de libros:\n",
        "  * **Scrap**: Para obtener los libros usando el Scrap, se debe acceder a dicha seccion y ejecutar el codigo, esto traera los libros, generara un df y lo guardara en formato csv.\n",
        "  * **Carga de archivo csv**: Cargar el archivo csv correspondiente al entorno de ejecucion, si se ejecuto anteriormente el Scrap, este archivo ya estara en el directorio.\n",
        "\n",
        "2) Declarar todas las funciones necesarias en las secciones **Procesamiento de texto**, **Buscar libros por reseña**, **Buscar libros por genero y autor**.\n",
        "\n",
        "3) Ejecutar el **Cliente**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cCwciTe1ZSB4"
      },
      "source": [
        "# Instalacion e importacion las librerias necesarias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "53se6zqkigK8",
        "outputId": "f70898bb-8a2d-42b7-d2d1-445d8ad34d82"
      },
      "outputs": [],
      "source": [
        "!pip install sentence-transformers\n",
        "!pip install fuzzywuzzy\n",
        "!pip install nltk\n",
        "!pip install python-Levenshtein"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VsEQ1QjUX2-w"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "import pandas as pd\n",
        "import random\n",
        "from fuzzywuzzy import process\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from transformers import BertTokenizer, BertModel\n",
        "from gensim.models import Word2Vec\n",
        "import unicodedata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "metadata": {
        "collapsed": true,
        "id": "jGNE4j-Yh3kK"
      },
      "outputs": [],
      "source": [
        "from sentence_transformers import SentenceTransformer, util\n",
        "# Función para obtener embeddings de oraciones\n",
        "def get_sentence_embeddings(sentences):\n",
        "    model = SentenceTransformer('msmarco-MiniLM-L-6-v3')\n",
        "    embeddings = model.encode(sentences)\n",
        "    return embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 133,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gw1-rt3hMz-W",
        "outputId": "52a37156-a8e2-472a-8f7f-3b3320a7d6b0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "23\n"
          ]
        }
      ],
      "source": [
        "generos = [\"ficcion\", \"historia\", \"misterio\", \"infantil\", \"arte\", \"economia\", \"humor\", \"poesia\", \"religion\", \"terror\", \"aventuras\", \"ciencia\", \"cuentos\", \"politica\", \"teatro\", \"tecnologia\", \"novela\", \"humor\", \"musica\", \"drama\", \"fantasia\", \"economia\", \"ciencia-ficcion\"]\n",
        "print(len(generos))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Is0TUr2hFRYy"
      },
      "source": [
        "# Scrap"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xtBvSmj184Ne"
      },
      "source": [
        "Realizamos el scrap a la pagina lectulandia con el objetivo de llenar nuestra base de datos con libros.\n",
        "Para esta aplicacion usamos la libreria BeautifulSoup4 ya que la estructura de la pagina no presentaba una gran dificultad y con las herramientas de dicha libreria era suficiente para encontrar y recopilar todo lo necesario.\n",
        "\n",
        "En primer lugar armamos las url correspondientes, definimos un objeto data con las claves Genero, Titulo, Autor y Descripcion que luego vamos a llenar con los datos correspondientes a cada libro.\n",
        "Tambien definimos una lista con todos los generos que deseamos incluir en nuestra base de datos de libros.\n",
        "\n",
        "Finalmente, iterando sobre la lista de generos, por cada genero ingresamos a la url de cada libro disponible, esto lo hicimos debido a que, extrayendo la informacion del libro desde la url del genero, la descripcion estaba incompleta, por lo que decidimos ingresar a cada libro para poder extraer todos sus datos completos.\n",
        "\n",
        "Finalmente convertimos el objeto data a un df de pandas, generamos los Embeddings para la descripcion de cada libro y lo almacenamos en una nueva columna llamada Embeddings y lo guardamos en un archivo csv."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 134,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Nsg3_IKrMyOH",
        "outputId": "9d454ad7-129a-4cf6-dcf0-2145dd9c4627"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# Obtener el contenido HTML de la página principal\n",
        "url_index = 'https://ww3.lectulandia.com'\n",
        "response_index = requests.get(url_index)\n",
        "html_content_index = response_index.text\n",
        "soup_index = BeautifulSoup(html_content_index, 'html.parser')\n",
        "\n",
        "# Armamos un objeto vacio donde vamos a ir almacenando los libros\n",
        "data = {'Genero': [],\n",
        "        'Titulo': [],\n",
        "        'Autor': [],\n",
        "        'Descripcion': []}\n",
        "\n",
        "# generos = [\"ficcion\", \"historia\", \"misterio\", \"infantil\", \"arte\", \"economia\", \"humor\", \"poesia\", \"religion\", \"terror\", \"aventuras\", \"ciencia\", \"cuentos\", \"politica\", \"teatro\", \"tecnologia\"]\n",
        "generos = [\"ficcion\", \"historia\", \"misterio\", \"infantil\", \"arte\", \"economia\", \"humor\", \"poesia\", \"religion\", \"terror\", \"aventuras\", \"ciencia\", \"cuentos\", \"politica\", \"teatro\", \"tecnologia\", \"novela\", \"humor\", \"musica\", \"drama\", \"fantasia\", \"economia\", \"ciencia-ficcion\"]\n",
        "\n",
        "# Encontramos el tag <section> con id 'secgenero' que es el que contiene a todos los generos\n",
        "soup_generos = soup_index.find('section', id='secgenero')\n",
        "\n",
        "# Iteramos la lista de generos, y obetenemos el enlace correspondiente\n",
        "for genero in generos:\n",
        "  # Buscamos el tag <a> que en e href contiene la url correspondiente\n",
        "  soup = soup_generos.find('a', href=f'/genero/{genero}/')\n",
        "  count_genero = 0\n",
        "  if soup:\n",
        "    # Construir el enlace completo y armamos un nuevo objeto soup\n",
        "    url_genero = url_index + soup[\"href\"]\n",
        "    response_genero = requests.get(url_genero)\n",
        "    html_content_genero = response_genero.text\n",
        "    soup_genero = BeautifulSoup(html_content_genero, 'html.parser')\n",
        "    # Encuentra todas las etiquetas <article> con la clase \"card\"\n",
        "    lista_articulos = soup_genero.find_all('article', class_='card')\n",
        "    for articulo in lista_articulos:\n",
        "      if count_genero == 24:\n",
        "        break\n",
        "      else:\n",
        "        enlace_card = articulo.find('a', class_='card-click-target')\n",
        "        href_value = enlace_card.get('href')\n",
        "        url_libro = url_index + href_value\n",
        "        response_libro = requests.get(url_libro)\n",
        "        html_content_libro = response_libro.text\n",
        "        soup_libro = BeautifulSoup(html_content_libro, 'html.parser')\n",
        "\n",
        "        titulo = soup_libro.find('div', id='title').find('h1').text.strip()\n",
        "        if titulo in data['Titulo']:\n",
        "          continue\n",
        "        else:\n",
        "          data['Titulo'].append(titulo)\n",
        "          data['Genero'].append(genero)\n",
        "          autor = soup_libro.find('div', id='autor').find('a').text.strip()\n",
        "          data['Autor'].append(autor)\n",
        "          desc = soup_libro.find('div', id='sinopsis').get_text(strip=True)\n",
        "          data['Descripcion'].append(desc)\n",
        "          count_genero += 1\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "df['Embeddings'] = df['Descripcion'].apply(lambda x: get_sentence_embeddings([x])[0])\n",
        "df.to_csv('df_libros.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KHZkoWxMRn8x"
      },
      "source": [
        "# Importacion de archivo csv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xJk8j4Vi8D7p"
      },
      "source": [
        "Definimos una funcion con el objetivo de convertir un str que contiene vectores a un objeto de np.array, esto debido a que, al cargar el dataset desde un archivo csv, el tipo de dato de la columna Embeddings es str y necesitamos que sea np.array para las aplicaciones del programa\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 135,
      "metadata": {
        "id": "wn6Ap6vuywd_"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "def cadena_a_arreglo_np(cadena):\n",
        "    cadena_limpia = cadena.replace(\"[\", \"\").replace(\"]\", \"\").replace(\"\\n\", \"\")\n",
        "    elementos = cadena_limpia.split()\n",
        "    elementos_numeros = [float(elem) for elem in elementos]\n",
        "    arreglo_np = np.array(elementos_numeros)\n",
        "    return arreglo_np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CryJPUrl-whl"
      },
      "source": [
        "Cargamos el df desde un archivo csv y convertimos la columan Embeddings a tipo de dato np.array con la funcion previamente declarada."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 136,
      "metadata": {
        "id": "yQpMnXkdNmi2"
      },
      "outputs": [],
      "source": [
        "df_libros = pd.read_csv('df_libros.csv')\n",
        "# Aplicar la función a toda la columna \"Embeddings\"\n",
        "df_libros['Embeddings'] = df_libros['Embeddings'].apply(cadena_a_arreglo_np)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m4JPqnOsRc1i"
      },
      "outputs": [],
      "source": [
        "df_libros"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tIjBmZnmBQtC"
      },
      "source": [
        "# Procesamiento de texto"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OeUphwwV_OAj"
      },
      "source": [
        "En esta seccion de  codigo definimos funciones utiles que usaremos proximamente.\n",
        "\n",
        "* **preprocess_text**: Es una funcion que recibe una cadena de texto y le aplica un procesamiento para dejarla lo mas limpia posible, unicamente con palabras clave, pasando el texto a minuscula, eliminando caracteres especiales, aplicando una tokenizacion con word_tokenize y filtrando palabras comunes, conectotores, etc. con stop_words de nltk.\n",
        "\n",
        "* **tokenizar_con_bert**: Funcion para tokenizar una cadena de texto con Bert Sentence Tokenizer, utilizamos este metodo porque nos parecio el mas completo y adecuado a la hora de tokenizar un fragmenteo de texto largo o un documento.\n",
        "\n",
        "* **Levenshtein_distance**: Funcion que recibe una palabra y una lista de palabras y devuelve la palabra de la lista que tiene la mayor similitud a la palabra ingresada usando la distancia de Levenshtein.\n",
        "\n",
        "* **encontrar_genero_similar**: Esta funcion la implementamos para pasar una frase o cadena de texto y detectar si dentro de ella hay una palabra que se asemeje a alguna de la lista de palabras pasada, usando la funcion previamente mencionada Levenshtein_distance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {
        "id": "KSR85kk5BUqi"
      },
      "outputs": [],
      "source": [
        "def preprocess_text(text):\n",
        "    # Convertir a minúsculas\n",
        "    text = text.lower()\n",
        "    # Eliminar caracteres especiales y números\n",
        "    text = re.sub(r'[^a-zA-Z\\sáéíóúüñ]', '', text)\n",
        "    # Tokenización\n",
        "    tokens = word_tokenize(text, language='spanish')\n",
        "    # Eliminar stopwords\n",
        "    stop_words = set(stopwords.words('spanish'))\n",
        "    filtered_tokens = [word for word in tokens if word not in stop_words]\n",
        "    # Reconstruir el texto preprocesado\n",
        "    preprocessed_text = ' '.join(filtered_tokens)\n",
        "    return preprocessed_text\n",
        "\n",
        "# Función para tokenizar el texto utilizando BERT (para las descripciones)\n",
        "def tokenizar_con_bert(texto):\n",
        "  # Cargar el tokenizador BERT pre-entrenado en español\n",
        "    tokenizer = BertTokenizer.from_pretrained(\"dccuchile/bert-base-spanish-wwm-cased\")\n",
        "    return tokenizer.tokenize(texto)\n",
        "\n",
        "# Función para tokenizar las sinopsis\n",
        "def tokenizar_con_wordtokenizer(texto):\n",
        "    return word_tokenize(texto.lower())\n",
        "\n",
        "# Funcion para tokenizar palabras (para genero y autor)\n",
        "def tokenizar_palabras(texto):\n",
        "    model = BertModel.from_pretrained('bert-base-multilingual-cased')\n",
        "    return model.tokenize(texto)\n",
        "\n",
        "import Levenshtein\n",
        "def Levenshtein_distance(palabra, lista_palabras):\n",
        "    mejor_similitud = float('inf')\n",
        "    palabra_similar = None\n",
        "    for palabra_lista in lista_palabras:\n",
        "        distancia = Levenshtein.distance(palabra, palabra_lista)\n",
        "        if distancia < mejor_similitud:\n",
        "            mejor_similitud = distancia\n",
        "            palabra_similar = palabra_lista\n",
        "    return palabra_similar\n",
        "\n",
        "def encontrar_genero_similar(frase, lista_generos):\n",
        "    palabras = frase.split()\n",
        "    genero_similar = None\n",
        "    mejor_distancia = float('inf')\n",
        "    for palabra in palabras:\n",
        "        palabra_similar = Levenshtein_distance(palabra, lista_generos)\n",
        "        distancia = Levenshtein.distance(palabra, palabra_similar)\n",
        "        if distancia < mejor_distancia:\n",
        "            mejor_distancia = distancia\n",
        "            genero_similar = palabra_similar\n",
        "    return genero_similar"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h8WGh86vF3um"
      },
      "source": [
        "# Buscar libros por **reseña**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NEQkGG1UA3rc"
      },
      "source": [
        "Definimos la funcion **similarity_descripcion** a la que le pasamos una cadena de texto, correspondiente a la solicitud del usuario, pasamos un df donde se encuentran todos nuestros libros y la cantidad que deseamos traer, por defecto son 3.\n",
        "\n",
        "Lo primero que hacemos es limpiar la entrada del usuario con la funcion **preprocess_text**.\n",
        "Traemos la lista de generos presentes en el df, a que genero se asimila la entrada de usuario usando la funcion **encontrar_genero_similar** y generamos un df con dicho genero.\n",
        "Generamos los Embeddings para la entrada del usuario usando la misma funcion usada para generar los embeddings de las descripciones de cada libro, buscamos las similitudes entre los embeddings usando la **distancia del coseno** y retornamos el top 3."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {
        "collapsed": true,
        "id": "wELk620_NCPp"
      },
      "outputs": [],
      "source": [
        "# Función para calcular similitud entre una consulta y descripciones\n",
        "def similarity_descripcion(user_query, df, top_n=3):\n",
        "    preprocessed_query = preprocess_text(user_query)\n",
        "    generos = df_libros['Genero'].unique()\n",
        "    genero_similar = encontrar_genero_similar(user_query, generos)\n",
        "    libros_genero = df[df['Genero'] == genero_similar]\n",
        "    query_embedding = get_sentence_embeddings([preprocessed_query])[0]\n",
        "    similarities = libros_genero['Embeddings'].apply(lambda x: util.cos_sim(query_embedding.astype(np.float64), x).item())\n",
        "    top_indices = similarities.nlargest(top_n).index\n",
        "    return df.iloc[top_indices][['Titulo', 'Autor', 'Genero', 'Descripcion']]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zTFr-Gl-FzGe"
      },
      "source": [
        "# Buscar libros por **Genero** y **Autor**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sX_5zDzPCiUx"
      },
      "source": [
        "Para la buqueda por genero y autor implementamos la misma logica, principalmente usando la funcion **Levenshtein_distance**.\n",
        "\n",
        "Las funciones **similarity_genero** y **similarity_autor** basicamente lo que hacen es tomar una entrada del usuario, un df para obtener todos los generos presentes en el mismo y retornar cual es el genero correspondiente o que mas se asimila al requerido por el usuario.\n",
        "\n",
        "Con las funciones **recomendar_libros_genero** y **recomendar_libros_autor** implementamos las funciones antes mencionadas para obtener el genero o autor correspondiente, filtramos y retornamos el df con los libros correspondientes a ese genero o autor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {
        "id": "JHNgNNGI8hw4"
      },
      "outputs": [],
      "source": [
        "# Función para calcular la palabra más cercana a la escrita y recomendar 3 libros de ese género\n",
        "def similarity_genero(user_query, df, top=3):\n",
        "    generos = df_libros['Genero'].unique()\n",
        "    genero_similar = Levenshtein_distance(user_query, generos)\n",
        "    return genero_similar\n",
        "\n",
        "def recomendar_libros_genero(user_genero, df, top=3):\n",
        "    generos = df_libros['Genero'].unique()\n",
        "    genero_similar = similarity_genero(user_genero, generos)\n",
        "    libros_recomendados_genero = df_libros[df_libros['Genero'] == genero_similar].head(top)\n",
        "    return libros_recomendados_genero"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {
        "id": "0oG_b_qp85UU"
      },
      "outputs": [],
      "source": [
        "# Función para calcular la palabra más cercana a la escrita y recomendar 3 libros de ese autor\n",
        "def similarity_autor(user_query, df, top=3):\n",
        "    autores = df_libros['Autor'].unique()\n",
        "    autor_similar = Levenshtein_distance(user_query, autores)\n",
        "    return autor_similar\n",
        "\n",
        "def recomendar_libros_autor(user_autor, df, top=3):\n",
        "    autores = df_libros['Autor'].unique()\n",
        "    autor_similar = similarity_autor(user_autor, autores)\n",
        "    libros_recomendados_autor = df_libros[df_libros['Autor'] == autor_similar].head(top)\n",
        "    libros_recomendados_autor.drop('Embeddings', axis=1, inplace=True)\n",
        "    return libros_recomendados_autor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p14n-aQTEpaD"
      },
      "source": [
        "# Cliente"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fx2mu8Qj2O_p",
        "outputId": "794a93f4-3f53-4e74-e06f-9b4a62b45071"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "¿Cómo deseas buscar? (reseña/autor/género): autor\n",
            "Ingresa el nombre del autor: Franz\n",
            "+---+---------+----------------+-------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|   | Genero  |     Titulo     |    Autor    |                                                                                                                                                                                                                                                                                                                                                  Descripcion                                                                                                                                                                                                                                                                                                                                                  |\n",
            "+---+---------+----------------+-------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| 0 | ficcion | Carta al padre | Franz Kafka | He aquí el inicio de una carta que constituye la piedra de toque y la clave de la concepción del mundo más angustiosa y atrayente del presente siglo:«Hace poco me preguntaste por qué digo que te tengo miedo. Como de costumbre, no supe darte una respuesta, en parte precisamente por el miedo que te tengo, en parte porque para explicar los motivos de ese miedo necesito muchos pormenores que no puedo tener medianamente presentes cuando hablo. Y si intento aquí responderte por escrito, sólo será de un modo muy imperfecto, porque el miedo y sus secuelas me disminuyen frente a ti, incluso escribiendo, y porque la amplitud de la materia supera mi memoria y mi capacidad de raciocinio». |\n",
            "+---+---------+----------------+-------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "from tabulate import tabulate\n",
        "\n",
        "# Solicitar al usuario cómo desea realizar la búsqueda\n",
        "search_type = input(\"¿Cómo deseas buscar? (reseña/autor/género): \").strip().lower()\n",
        "\n",
        "if search_type == \"reseña\" or search_type == \"resenia\":\n",
        "    user_query = input(\"Ingresa tu consulta por reseña: \")\n",
        "    recommended_books = similarity_descripcion(str(user_query), df_libros)\n",
        "elif search_type == \"autor\":\n",
        "    author_name = input(\"Ingresa el nombre del autor: \").strip()\n",
        "    recommended_books = recomendar_libros_autor(author_name, df_libros)\n",
        "elif search_type == \"género\" or search_type == \"genero\":\n",
        "    genre = input(\"Ingresa el género literario: \").strip()\n",
        "    recommended_books = recomendar_libros_genero(genre, df_libros)\n",
        "else:\n",
        "    recommended_books = \"Opción de búsqueda no válida.\"\n",
        "\n",
        "# Mostrar resultados en una tabla\n",
        "if isinstance(recommended_books, pd.DataFrame):\n",
        "    print(tabulate(recommended_books.drop(columns=['Embeddings', 'similarity'], errors='ignore'), headers='keys', tablefmt='pretty'))\n",
        "else:\n",
        "    print(recommended_books)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cVl0VgtbFnOH"
      },
      "source": [
        "# Conclusiones finales"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H4kGbTYtGXuP"
      },
      "source": [
        "### Scrap\n",
        "\n",
        "Consideramos que el scrap realizado funciona bien y cumple con lo requerido, sin embargo es muy mejorable, principalmente en la fuente y la forma en la que recopila y trae los libros. Nosotros lo hicimos ingresando por genero y le asigna un genero a cada uno, por ahi una mejor opcion era agarrar libros desde el index y almacenar en la columna Genero un array con sus generos ya que apreciamos en la pagina que por lo general cada libro tiene mas de un genero, tambien se podria implementar una funcion donde se ingrese unicamente la url y la cantidad de libros requerida, como asi muchas mejoras mas, por cuestiones de tiempo optamos por dejarlo asi ya que funciona bien y cumple con el objetivo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xpwuSD4iHN33"
      },
      "source": [
        "### Obtener libros por **Reseña**\n",
        "\n",
        "Al principio experimentamos problemas debido a que nuestra basde de datos de libros era muy acotada, lo que hacia que a la hora de buscar, no encontrara las coincidencias mas acordes, por ejemplo, a la hora de buscar \"libros de terror\" generalmente encontraba 1 o 2 libros acordes y uno que nada tenia que ver con lo solicitado.\n",
        "\n",
        "Decidimos implementar un poco de los metodos utilizados en la busqueda por genero y detectamos dentro de la entrada del usuario, alguna palabra con cercania con alguno de los los generos presentes en nuestra base de datos, esto nos facilita nos facilita la posterior busqueda por similitud acotando la lista de libros.\n",
        "Finalmente calculamos la distancia entre los embeddings de la entrada y los embeddings de la descripcion de cada libro y obtenemos los 3 primeros.\n",
        "\n",
        "De esta forma logramos obtener una respuesta mas cercana a lo solicitado, sin embargo, es alta la posibilidad de detectar una palabra incorrecta a la hora de ecnontrar un genero y hacer que falle, tambien, otra falencia podria ser que se encuentra ligado directamente a una busqueda interna de genero.\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
